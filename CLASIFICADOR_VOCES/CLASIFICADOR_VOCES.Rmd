---
title: Proyecto de Clasificación de Voces de Personas
author:
  - name: Luis Albacete Caballero
    email: alcaluis@alumni.uv.es
    affiliation: UV
  - name: Julio García Bustos
    email: jugarbus@alumni.uv.es
    affiliation: UV
  - name: Gabriel Ivars Asensio
    email: bob@example.com
    affiliation: UV
  - name: Noé López García
    email: bob@example.com
    affiliation: UV
  - name: José Miguel Palazón Caballero
    email: jomipaca@alumni.uv.es
    affiliation: UV
  - name: Joan Pedro Bruixola
    email: jopebrui@alumni.uv.es
    affiliation: UV
address:
  - code: UV
    organization: Universitat de València
    addressline: Avinguda de l'Universitat
    city: Burjassot
    state: Valencia
    postcode: 46100
    country: España
abstract: |
  Esto es un ejemplo de texto en la sección "Abstract".
keywords: 
  - Voces
  - Características
  - Características de la voz
  - Clasificación
  - Aprendizaje Máquina
  - Análisis de Señales
  - Identificación voces
date: "`r Sys.Date()`"
linenumbers: false
numbersections: true
output: 
  rticles::elsevier_article:
    keep_tex: true
    citation_package: natbib
---

```{r setup, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE,
                      #warning=FALSE,
                      out.width = "80%",
                      fig.align = "center")

# Cargar librerías
librerias <- c("tuneR",      # Lectura de archivos WAV
               "seewave",    # Manipulación mediante wavelets
               "plotly",     # Gráficos 3D
               "phonTools",  # Libreria para obtención de Formants
               "dplyr",      # Manipulacion de datos
               "kableExtra", # Kable para ajutar las tablas
               "wavelets",   # Libreria para manipulación con Wavelets
               "signal",     # Funciones de procesado de señales
               "ggplot2",    # Librería de gráficos
               "ggpubr",     # Mostrar múltiples ggplots juntos
               "lomb"
              )
pacman::p_load(char = librerias, warn.conflicts=FALSE)

# Cargar utilidades
source("../Utils/extraccion_caracteristicas.R")
source("../Utils/carga_datos.R")
```

```{r limpieza_audios}
# Cargar datos + Metadatos
# w <- readWave("../Data/whatstheweatherlike.wav") # Audio ejemplo
carga <- carga_audios("../Data/Audios/")
audios <- carga[[1]]
meta_audios <- carga[[2]]

library(wavelets)

# 1. Eliminación ruido
audios <- limpieza_senales(audios)

# 2. Normalización
audios <- normalizacion(audios)

# 3. DataFrame características
df_caract <- data.frame("id_audio" = meta_audios$id_audio)
```

# Característica de la voz

## Característica ejemplo

```{r extraccion_caract_ejemplo}
# WIP
ste_c <- rep(0.0, length(audios))
id <- 1

for (audio in audios) {
  ste_c[id] <- mean(STE(audio, audio@samp.rate * 0.02, 50)[,2])
  id = id + 1
}

# Agregar caracteristica
df_caract <- cbind(df_caract, ste_c)
```

## Harmonic-to-Noise Ratio (HNR)

Esta característica mide la proporción entre la energía de la componente armónica de la señal respecto al ruido presente. Aunque su principal uso es en el área de la sanidad para detectar patologías mediante la voz, también nos puede ayudar a distinguir la claridad y ciertas particularidades de las voces.

Para ello, nos ayudaremos de la descomposición mediante wavelets para separar las Aproximaciones (componente de baja frecuencia de la señal normalmente interpretada como la parte harmónica) de los Detalles (componente de alta frecuencia relacionada con el ruido).

```{r extraccion_caract_HNR, warning=FAÑSE}

HNR_carac <- rep(0.0, length(audios))
id <- 1

for (audio in audios) {
  # Calcular HNR para la señal y almacenarla
  HNR_carac[id] <- HNR(audio)
  
  # Incrementar el contador
  id <- id + 1
}

# Agregar la característica HNR al marco de datos
df_caract <- cbind(df_caract, HNR_carac)
```

```{r}
df <- df_caract %>%
  left_join(meta_audios, by = "id_audio")  # Combinar los datos
# Reordenar los niveles de los locutores
df$locutor <- factor(df$locutor, levels = c("01", "02", "03", "05", "06","04" ,"07", "08", "09", "10"))
```

```{r}
ggplot(df, aes(x = HNR_carac, fill = genero)) +
  geom_density(alpha = 0.5) +  # Curvas de densidad
  labs(
    title = "Distribución de HNR por GéneroS",
    x = "HNR",
    y = "Densidad",
    fill = "Género"
  ) +
  theme_minimal()
```

El gráfico muestra una clara diferencia de tendencia entre géneros; mientras que las voces masculinas suelen encontrarse más cerca de una supuesta media, el HNR de las voces femeninas está distribuido de forma más uniforme en el rango de valores. De esta forma, valores de HNR cercanos a los extremos podrían indicar mayor probabilidad de que la voz grabada sea femenina y valores cercanos a la media lo contrario. No obstante, esta diferencia de tendencias según el género no es muy evidente o conlcuyente, por lo que este indicador por si mismo puede que no sea suficiente pero potencialmente puede aportar información relevante a un algoritmo de clasificación.


# Algoritmos de ML

## Clustering

```{r algoritmos_clustering}
# WIP
```

## Clasificación

```{r algoritmos_clasificacion}
# WIP
```



