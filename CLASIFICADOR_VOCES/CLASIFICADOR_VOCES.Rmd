---
title: Proyecto de Clasificación de Voces de Personas
author:
  - name: Luis Albacete Caballero
    email: alcaluis@alumni.uv.es
    affiliation: UV
  - name: Julio García Bustos
    email: jugarbus@alumni.uv.es
    affiliation: UV
  - name: Gabriel Ivars Asensio
    email: bob@example.com
    affiliation: UV
  - name: Noé López García
    email: bob@example.com
    affiliation: UV
  - name: José Miguel Palazón Caballero
    email: bob@example.com
    affiliation: UV
  - name: Joan Pedro Bruixola
    email: jopebrui@alumni.uv.es
    affiliation: UV
address:
  - code: UV
    organization: Universitat de València
    addressline: Avinguda de l'Universitat
    city: Burjassot
    state: Valencia
    postcode: 46100
    country: España
abstract: |
  Esto es un ejemplo de texto en la sección "Abstract".
keywords: 
  - Voces
  - Características
  - Características de la voz
  - Clasificación
  - Aprendizaje Máquina
  - Análisis de Señales
  - Identificación voces
date: "`r Sys.Date()`"
linenumbers: false
numbersections: true
output: 
  rticles::elsevier_article:
    keep_tex: true
    citation_package: natbib
---

```{r setup, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE,
                      #warning=FALSE,
                      out.width = "80%",
                      fig.align = "center")

# Cargar librerías
librerias <- c("tuneR",    # Lectura de archivos WAV
               "seewave"   # Manipulación mediante wavelets
              )
pacman::p_load(char = librerias)

# Cargar utilidades
source("../Utils/extraccion_caracteristicas.R")
source("../Utils/carga_datos.R")
```

```{r limpieza_audios}
# Cargar datos + Metadatos
# w <- readWave("../Data/whatstheweatherlike.wav") # Audio ejemplo
carga <- carga_audios("../Data/Audios/")
audios <- carga[[1]]
meta_audios <- carga[[2]]

library(wavelets)

# 1. Eliminación ruido
audios <- limpieza_senales(audios)

# 2. Normalización
audios <- normalizacion(audios)

# 3. DataFrame características
df_caract <- data.frame("id_audio" = meta_audios$id_audio)
```

# Característica de la voz

## Característica ejemplo

```{r extraccion_caract_ejemplo}
# WIP
ste_c <- rep(0.0, length(audios))
id <- 1

for (audio in audios) {
  ste_c[id] <- mean(STE(audio, audio@samp.rate * 0.02, 50)[,2])
  id = id + 1
}

# Agregar caracteristica
df_caract <- cbind(df_caract, ste_c)
```

## Característica 1

A continuación, vamos a extraer la Short-Time Energy (STE) de cada uno de nuestros audios y analizaremos las diferencias para cada locutor y cada género. La Short-Time Energy (STE) mide la energía contenida en una señal dentro de pequeñas ventanas temporales. Puede ser muy útil para analizar variaciones de energía a lo largo del tiempo. Para nuestro caso, puede ser particularmente interesante porque las variaciones de energía a lo largo del tiempo pueden reflejar características importantes de la voz humana, como la intensidad, los patrones de habla y las pausas.


El procedimiento que hemos seguido consiste en tomar cada señal (audio) y dividirla en ventanas temporales. Luego, calculamos la energía cuadrática media para cada ventana y la normalizamos. Finalmente, promediamos los valores de STE normalizados obtenidos en cada áudio para obtener un único valor representativo por audio.


```{r extraccion_caract_1}
# WIP
ste_c <- rep(0.0, length(audios))
id <- 1

for (audio in audios) {
  ste_c[id] <- mean(STE(audio, audio@samp.rate * 0.02, 50)[,2])
  id = id + 1
}

# Agregar caracteristica
df_caract <- cbind(df_caract, ste_c)
```

```{r}
df <- df_caract %>%
  left_join(meta_audios, by = "id_audio")  # Combinar los datos
# Reordenar los niveles de los locutores
df$locutor <- factor(df$locutor, levels = c("01", "02", "03", "05", "06","04" ,"07", "08", "09", "10"))
 

```

```{r}

ggplot(df, aes(x = locutor, y = ste_c, color = genero)) +
  geom_point(size = 3, alpha = 0.8) +  # Puntos
  geom_boxplot(aes(group = genero), alpha = 0.3) +  # Boxplots por género
  labs(
    title = "Short-Time Energy (STE) por Locutor y Género",
    x = "Locutor",
    y = "Short-Time Energy (STE)",
    color = "Género"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))




```

Observamos que las locutoras tienen una mayor variabilidad en la STE en comparación con los locutores hombres. Esto podría deberse a características propias de las voces femeninas, como el rango de modulación, que es más amplio. Además, las locutoras presentan valores de STE más altos en general. Esto se refleja en una mediana de aproximadamente 0.10, mientras que en los locutores hombres la mediana se encuentra alrededor de 0.07. Esto puede tener relación con la frecuencia fundamental. Las voces femeninas suelen tener una frecuencia fundamental más alta que las voces masculinas. Dado que la STE mide la energía de la señal acústica, una frecuencia fundamental más alta puede generar más energía en las frecuencias superiores, lo que puede reflejarse en un valor más alto de STE.



```{r}

ggplot(df, aes(x = ste_c, fill = genero)) +
  geom_density(alpha = 0.5) +  # Curvas de densidad
  labs(
    title = "Distribución de STE por Género",
    x = "Short-Time Energy (STE)",
    y = "Densidad",
    fill = "Género"
  ) +
  theme_minimal()

```


Las curvas de densidad muestran que las voces femeninas tienen una distribución más amplia y desplazada hacia valores más altos de STE, lo que confirma lo que hemos visto en el boxplot. Los locutores hombres, por otro lado, presentan una distribución más concentrada y con menor dispersión. Aunque hay diferencias entre géneros, también se observa cierto solapamiento en las densidades de STE. Esto indica que, si bien hay tendencias generales, la STE por sí sola puede no ser completamente discriminativa entre géneros en todos los casos.

En conclusión, los resultados sugieren que la Short-Time Energy es una métrica que capta diferencias significativas entre géneros, aunque también está influenciada por características individuales.








## Característica 2


El Linear Predictive Coding (LPC) es un modelo matemático que describe una señal de audio en función de una combinación lineal de sus valores pasados. En lugar de representar la señal de audio directamente, se modela como una secuencia de coeficientes que predicen el valor futuro de la señal basándose en los valores previos. Los coeficientes LPC son los parámetros que caracterizan este modelo de predicción lineal. En el contexto de la LPCC, los coeficientes son derivados a partir de los coeficientes LPC mediante una transformación matemática, y son usados frecuentemente como una representación compacta y eficiente de la información espectral de la señal. Nuestro objetivo es analizar si los coeficientes obtenidos para los áudios con locutores hombres tienen patrones distintos a los obtenidos para las locutoras.

Para obtener los coeficientes LPCC seguiremos los siguientes pasos:

1) Preprocesamiento de la señal: La señal de audio se segmenta en ventanas de corto tiempo (frames) para su análisis.

2) Cálculo de los coeficientes LPC: A partir de cada segmento de la señal, se calcula un conjunto de coeficientes LPC (usaremos la función lpc). Estos coeficientes describen cómo la señal futura puede ser predicha a partir de los valores anteriores.

3) Transformación a LPCC: Una vez obtenidos los coeficientes LPC, se aplican transformaciones matemáticas (como la transformada cepstral) para obtener los coeficientes LPCC. 

Calcularemos los coeficientes para cada ventana de cada áudio con la función "calc_lpcc", que aplica los pasos anteriores para obtenerlos. Usaremos orden 4, lo que significa que obtendremos 4 coeficientes por ventana.

```{r}

# Parámetros
frame_size <- 512  # Tamaño del frame
overlap <- 128     # Solapamiento
order <- 4        # Orden de LPC

# Aplicar la función a todos los audios y calcular los LPCCs
lpcc_results <- lapply(audios, function(wav) {
  signal <- as.vector(wav@left)  # Convertir audio a vector (usando el canal 'left' para señales mono)
  calc_lpcc(signal, frame_size, overlap, order)
})


```


```{r}

library(tidyr)

df_list <- lapply(1:length(lpcc_results), function(i) {
  # Para cada audio, expandimos cada ventana y sus coeficientes LPCC
  audio_lpcc <- lpcc_results[[i]]
  # Convertir cada ventana (lista de 4 coeficientes) en un dataframe de 4 columnas
  audio_df <- do.call(rbind, lapply(audio_lpcc, function(window) {
    data.frame(lpcc_1 = window[1], lpcc_2 = window[2], lpcc_3 = window[3], lpcc_4 = window[4])
  }))
  
  # Agregar una columna 'audio_id' para identificar el audio
  audio_df$id_audio <- i
  return(audio_df)
})

# Combinar todas las listas de dataframes en uno solo
final_df <- do.call(rbind, df_list)

df_totales <- final_df %>%
  left_join(meta_audios, by = "id_audio")  # Combinar los datos
# Reordenar los niveles de los locutores
df_totales$locutor <- factor(df_totales$locutor, levels = c("01", "02", "03", "05", "06","04" ,"07", "08", "09", "10"))
 

```

El siguiente DataFrame guarda la media y la desviación estándar de los coeficientes obtenidos para cada audio.

```{r}

  df <- df_totales %>%
  group_by(id_audio,genero,pista,locutor) %>%
  summarise(
    lpcc_1_mean = mean(lpcc_1), lpcc_1_sd = sd(lpcc_1),
    lpcc_2_mean = mean(lpcc_2), lpcc_2_sd = sd(lpcc_2),
    lpcc_3_mean = mean(lpcc_3), lpcc_3_sd = sd(lpcc_3),
    lpcc_4_mean = mean(lpcc_4), lpcc_4_sd = sd(lpcc_4)
  )

# Ver el dataframe resultante
head(df)


```

A continuación, analizaremos si es posible identificar patrones en los coeficientes que permitan discernir el género del locutor.

Vamos a filtrar por la pista de áudio y veremos si se aprecian diferencias entre la media y la desviación estándar en función del género del locutor. 

```{r}

# Resumen descriptivo de los coeficientes LPCC por género
library(dplyr)

# Calcular estadísticas descriptivas por género
summary_stats <-df_totales %>%
  filter(pista=='02') %>%
  group_by(genero) %>%
  summarise(
    lpcc_1_mean = mean(lpcc_1), lpcc_1_sd = sd(lpcc_1),
    lpcc_2_mean = mean(lpcc_2), lpcc_2_sd = sd(lpcc_2),
    lpcc_3_mean = mean(lpcc_3), lpcc_3_sd = sd(lpcc_3),
    lpcc_4_mean = mean(lpcc_4), lpcc_4_sd = sd(lpcc_4),
  )

# Ver las estadísticas
summary_stats

```

```{r}

# Suponiendo que tu dataframe se llama df_coefs
knitr::kable(summary_stats, format = "latex", 
             booktabs = TRUE, 
             caption = "Media y desviación estándar de los coeficientes LPCC por género", 
             align = 'ccccccccc',  # Ajusta según el número de columnas
             centering = TRUE,
             table.envir = "table", position = "H")


```



```{r}

# Resumen descriptivo de los coeficientes LPCC por género
library(dplyr)

# Calcular estadísticas descriptivas por género
summary_stats <-df_totales %>%
  filter(pista=='03') %>%
  group_by(genero) %>%
  summarise(
    lpcc_1_mean = mean(lpcc_1), lpcc_1_sd = sd(lpcc_1),
    lpcc_2_mean = mean(lpcc_2), lpcc_2_sd = sd(lpcc_2),
    lpcc_3_mean = mean(lpcc_3), lpcc_3_sd = sd(lpcc_3),
    lpcc_4_mean = mean(lpcc_4), lpcc_4_sd = sd(lpcc_4),
  )

# Ver las estadísticas
summary_stats

# Suponiendo que tu dataframe se llama df_coefs
knitr::kable(summary_stats, format = "latex", 
             booktabs = TRUE, 
             caption = "Media y desviación estándar de los coeficientes LPCC por género", 
             align = 'ccccccccc',  # Ajusta según el número de columnas
             centering = TRUE,
             table.envir = "table", position = "H")


```



```{r}

# Resumen descriptivo de los coeficientes LPCC por género
library(dplyr)

# Calcular estadísticas descriptivas por género
summary_stats <-df_totales %>%
  filter(pista=='05') %>%
  group_by(genero) %>%
  summarise(
    lpcc_1_mean = mean(lpcc_1), lpcc_1_sd = sd(lpcc_1),
    lpcc_2_mean = mean(lpcc_2), lpcc_2_sd = sd(lpcc_2),
    lpcc_3_mean = mean(lpcc_3), lpcc_3_sd = sd(lpcc_3),
    lpcc_4_mean = mean(lpcc_4), lpcc_4_sd = sd(lpcc_4),
  )

# Ver las estadísticas
summary_stats

# Suponiendo que tu dataframe se llama df_coefs
knitr::kable(summary_stats, format = "latex", 
             booktabs = TRUE, 
             caption = "Media y desviación estándar de los coeficientes LPCC por género", 
             align = 'ccccccccc',  # Ajusta según el número de columnas
             centering = TRUE,
             table.envir = "table", position = "H")


```


Notamos que ciertos patrones se repiten para todas las pistas de áudio. La media de los coeficientes 2 y 4 correspondientes a los chicos es mayor que la de las chicas en todas las pistas, mientras que con el coeficiente 3 pasa al contrario. También podemos destacar que la desviación estándar de los coeficientes es en todos los casos superior para los locutores chicos que para las chicas. 











## Característica N

```{r extraccion_caract_n}
# WIP
```

# Algoritmos de ML

## Clustering

```{r algoritmos_clustering}
# WIP
```

## Clasificación

```{r algoritmos_clasificacion}
# WIP
```



