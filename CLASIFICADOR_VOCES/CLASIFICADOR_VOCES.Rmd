---
title: Proyecto de Clasificación de Voces de Personas
author:
  - name: Luis Albacete Caballero
    email: alcaluis@alumni.uv.es
    affiliation: UV
  - name: Julio García Bustos
    email: jugarbus@alumni.uv.es
    affiliation: UV
  - name: Gabriel Ivars Asensio
    email: bob@example.com
    affiliation: UV
  - name: Noé López García
    email: bob@example.com
    affiliation: UV
  - name: José Miguel Palazón Caballero
    email: jomipaca@alumni.uv.es
    affiliation: UV
  - name: Joan Pedro Bruixola
    email: jopebrui@alumni.uv.es
    affiliation: UV
address:
  - code: UV
    organization: Universitat de València
    addressline: Avinguda de l'Universitat
    city: Burjassot
    state: Valencia
    postcode: 46100
    country: España
abstract: |
  Esto es un ejemplo de texto en la sección "Abstract".
keywords: 
  - Voces
  - Características
  - Características de la voz
  - Clasificación
  - Aprendizaje Máquina
  - Análisis de Señales
  - Identificación voces
date: "`r Sys.Date()`"
linenumbers: false
numbersections: true
output: 
  rticles::elsevier_article:
    keep_tex: true
    citation_package: natbib
---

```{r setup, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE,
                      #warning=FALSE,
                      out.width = "80%",
                      fig.align = "center")

# Cargar librerías
librerias <- c("tuneR",      # Lectura de archivos WAV
               "seewave",    # Manipulación mediante wavelets
               "plotly",     # Gráficos 3D
               "phonTools",  # Libreria para obtención de Formants
               "dplyr",      # Manipulacion de datos
               "kableExtra", # Kable para ajutar las tablas
               "wavelets",   # Libreria para manipulación con Wavelets
               "signal",     # Funciones de procesado de señales
               "ggplot2",    # Librería de gráficos
               "ggpubr",     # Mostrar múltiples ggplots juntos
               "lomb"
              )
pacman::p_load(char = librerias, warn.conflicts=FALSE)

# Cargar utilidades
source("../Utils/extraccion_caracteristicas.R")
source("../Utils/carga_datos.R")
```

```{r limpieza_audios}
# Cargar datos + Metadatos
# w <- readWave("../Data/whatstheweatherlike.wav") # Audio ejemplo
carga <- carga_audios("../Data/Audios/")
audios <- carga[[1]]
meta_audios <- carga[[2]]

library(wavelets)

# 1. Eliminación ruido
audios <- limpieza_senales(audios)

# 2. Normalización
audios <- normalizacion(audios)

# 3. DataFrame características
df_caract <- data.frame("id_audio" = meta_audios$id_audio)
```

# Característica de la voz

## Característica ejemplo

```{r extraccion_caract_ejemplo}
# WIP
ste_c <- rep(0.0, length(audios))
id <- 1

for (audio in audios) {
  ste_c[id] <- mean(STE(audio, audio@samp.rate * 0.02, 50)[,2])
  id = id + 1
}

# Agregar caracteristica
df_caract <- cbind(df_caract, ste_c)
```

## Harmonic-to-Noise Ratio (HNR)

Esta característica mide la proporción entre la energía de la componente armónica de la señal respecto al ruido presente. Aunque su principal uso es en el área de la sanidad para detectar patologías mediante la voz, también nos puede ayudar a distinguir la claridad y ciertas particularidades de las voces.

Para ello, nos ayudaremos de la descomposición mediante wavelets para separar las Aproximaciones (componente de baja frecuencia de la señal normalmente interpretada como la parte harmónica) de los Detalles (componente de alta frecuencia relacionada con el ruido).

```{r extraccion_caract_HNR, warning=FAÑSE}

HNR_carac <- rep(0.0, length(audios))
id <- 1

for (audio in audios) {
  # Calcular HNR para la señal y almacenarla
  HNR_carac[id] <- HNR(audio)
  
  # Incrementar el contador
  id <- id + 1
}

# Agregar la característica HNR al marco de datos
df_caract <- cbind(df_caract, HNR_carac)
```

```{r}
df <- df_caract %>%
  left_join(meta_audios, by = "id_audio")  # Combinar los datos
# Reordenar los niveles de los locutores
df$locutor <- factor(df$locutor, levels = c("01", "02", "03", "05", "06","04" ,"07", "08", "09", "10"))
```

```{r}
ggplot(df, aes(x = HNR_carac, fill = genero)) +
  geom_density(alpha = 0.5) +  # Curvas de densidad
  labs(
    title = "Distribución del Harmonic-to-Noise Ratio (HNR) por Género",
    x = "Harmonic-to-Noise Ratio (HNR)",
    y = "Densidad",
    fill = "Género"
  ) +
  theme_minimal()
```

```{r}
ggplot(df, aes(x = locutor, y = HNR_carac, color = genero)) +
  geom_point(size = 3, alpha = 0.8) +  # Puntos
  geom_boxplot(aes(group = genero), alpha = 0.3, outlier.shape = NA) +  # Boxplots por género
  labs(
    title = "Harmonic-to-Noise Ratio (HNR) por Locutor y Género",
    x = "Locutor",
    y = "Harmonic-to-Noise Ratio (HNR)",
    color = "Género"
  )  +  
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
```

El gráfico de distribución de densidades muestra una clara diferencia de tendencia entre géneros; mientras que las voces masculinas suelen encontrarse más cerca de la media cercana a 62, el HNR de las voces femeninas está distribuido de forma más uniforme en el rango de valores. De esta forma, valores de HNR cercanos a los extremos podrían indicar mayor probabilidad de que la voz grabada sea femenina y valores cercanos a la media lo contrario. No obstante, esta diferencia de tendencias según el género no es muy evidente o conlcuyente, por lo que este indicador por si mismo puede que no sea suficiente pero potencialmente puede aportar información relevante a un algoritmo de clasificación.

Centrándonos en el HNR según locutor, podemos ver que en el caso del género femenino hay cierta constancia en los valores, agrupándose en un rango no muy amplio que podría ayudar a su identificación. En cuánto al género masculino, sus HNR se encuentran distribuidos en intervalos semejantes por lo que podría ser considerablemente difícil discernir entre locutores masculinos.

## Centroides Espectrales (CE)

Esta medida pretende caracterizar el espectro del audio señalando el "centro de masa" de su energía. Dicho centro se calcula realizando la media ponderada de las frecuencias encontradas usando una transformada de Fourier y usando sus amplitudes como pesos. 

El centroide espectral de un audio tiene profunda relación con el timbre del mismo, en particular con su "brightness"; esta característica puede ser muy útil a la hora de diferenciar entre géneros e incluso de identificar patrones únicos en cada locutor.

Para su implementación en R nos ayudaremos de la librería seewave, la cual cuenta con esta medida dentro del resumen de estadísticas presentes en la función "specprop".

```{r extraccion_caract_CE, warning=FAÑSE}

CE_carac <- rep(0.0, length(audios))
id <- 1

for (audio in audios) {
  # Calcular CE para la señal y almacenarla
  CE_carac[id] <- CE(audio)
  
  # Incrementar el contador
  id <- id + 1
}

# Agregar la característica HNR al marco de datos
df_caract <- cbind(df_caract, CE_carac)
```

```{r}
df <- df_caract %>%
  left_join(meta_audios, by = "id_audio")  # Combinar los datos
# Reordenar los niveles de los locutores
df$locutor <- factor(df$locutor, levels = c("01", "02", "03", "05", "06","04" ,"07", "08", "09", "10"))
```

```{r}
ggplot(df, aes(x = CE_carac, fill = genero)) +
  geom_density(alpha = 0.5) +  # Curvas de densidad
  labs(
    title = "Distribución del Centroide Espectral (CE) por Género",
    x = "Centroide Espectral (CE)",
    y = "Densidad",
    fill = "Género"
  ) +
  theme_minimal()
```

```{r}
ggplot(df, aes(x = locutor, y = CE_carac, color = genero)) +
  geom_point(size = 3, alpha = 0.8) +  # Puntos
  geom_boxplot(aes(group = genero), alpha = 0.3, outlier.shape = NA) +  # Boxplots por género
  labs(
    title = "Centroide Espectral (CE) por Locutor y Género",
    x = "Locutor",
    y = "Centroide Espectral (CE)",
    color = "Género"
  )  +  
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
```

Notamos un comportamiento muy semejante al de la característica Harmonic-to-Noise Ratio (HNR): los CE de las voces masculinas se encuentran mucho más concentrados en torno a una media cercana a 175 mientras que las voces femeninas se reparten de forma más homogénea a lo largo del rango total 100-260, teniendo dos máximos locales en 120 y 230.

En cuánto al análisis por locutor, podemos observar considerable variabilidad de centroides espectrales dependiendo del audio (salvo en el caso del locutor 01), lo que puede dificultar el uso de esta medida para la identificación concreta del locutor. Sin embargo, al igual que en características anteriores la diferencia de distribución de densidad entre géneros puede aportar información relevante a la hora de clasificarlos.

# Algoritmos de ML

## Clustering

```{r algoritmos_clustering}
# WIP
```

## Clasificación

```{r algoritmos_clasificacion}
# WIP
```



